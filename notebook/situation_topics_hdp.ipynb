{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from docx import Document\n",
    "from io import StringIO, BytesIO\n",
    "import re\n",
    "import time\n",
    "import datetime\n",
    "\n",
    "import pandas as pd\n",
    "import json\n",
    "import spacy\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "from gensim.models import LdaModel\n",
    "from gensim.models.wrappers import LdaMallet\n",
    "import gensim.corpora as corpora\n",
    "from gensim.corpora import Dictionary\n",
    "from gensim import matutils, models\n",
    "from gensim.models import CoherenceModel, TfidfModel, HdpModel\n",
    "from gensim.models.phrases import Phrases, Phraser\n",
    "import pyLDAvis.gensim\n",
    "\n",
    "from docx import Document\n",
    "from io import StringIO, BytesIO\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.rcParams.update({'font.size': 14, 'lines.linewidth': 3})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "# stop_words = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "notebook_dir = os.getcwd()\n",
    "situ_df = pd.read_csv('../data/interim/all_situation.csv', \n",
    "                      keep_default_na = False, \n",
    "                     converters = {#'situation': eval, \n",
    "                                   'sop': eval})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>role</th>\n",
       "      <th>situation</th>\n",
       "      <th>sop</th>\n",
       "      <th>filename</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>call taker</td>\n",
       "      <td>CBSA alarm policy</td>\n",
       "      <td>[Listen to alarm, Acknowledge the alarm by pre...</td>\n",
       "      <td>DE - 1033 - Officer in trouble.docx</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>call taker</td>\n",
       "      <td>All other DOMI reports</td>\n",
       "      <td>[Create a call in every instance. Do not cance...</td>\n",
       "      <td>AB - DOMI - Domestic in progress.docx</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>call taker</td>\n",
       "      <td>GPS Panic Alarms</td>\n",
       "      <td>[Create a call, Remain on the line recording a...</td>\n",
       "      <td>AB - DOMI - Domestic in progress.docx</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>call taker</td>\n",
       "      <td>Address Obtained</td>\n",
       "      <td>[Run address on QBA:, If the person is negativ...</td>\n",
       "      <td>AB - FOUNDP - Found Person.docx</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>call taker</td>\n",
       "      <td>Name or medic alert is known</td>\n",
       "      <td>[Run name on CPIC, If the person is negative o...</td>\n",
       "      <td>AB - FOUNDP - Found Person.docx</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3589</th>\n",
       "      <td>call taker</td>\n",
       "      <td>All Other DVERS personal residential alarms</td>\n",
       "      <td>[Create a call, Check hazards which will show ...</td>\n",
       "      <td>AB - ALARMD - Domestic violence alarm.docx</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3590</th>\n",
       "      <td>call taker</td>\n",
       "      <td>DVERS Alarm maintenance</td>\n",
       "      <td>[See “Assist GP”  for a stand by keep the peac...</td>\n",
       "      <td>AB - ALARMD - Domestic violence alarm.docx</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3591</th>\n",
       "      <td>call taker</td>\n",
       "      <td>GPS tracked Panic Alarms</td>\n",
       "      <td>[See AB-DOMI]</td>\n",
       "      <td>AB - ALARMD - Domestic violence alarm.docx</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3592</th>\n",
       "      <td>call taker</td>\n",
       "      <td>DNA Warrant:</td>\n",
       "      <td>[See WARRAN (Warrants) SOP]</td>\n",
       "      <td>NW - DNA - DNA collection .docx</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3593</th>\n",
       "      <td>call taker</td>\n",
       "      <td>DNA Warrant:</td>\n",
       "      <td>[See WARRAN (Warrants) SOP]</td>\n",
       "      <td>RI - DNA - DNA collection.docx</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3594 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            role                                    situation  \\\n",
       "0     call taker                            CBSA alarm policy   \n",
       "1     call taker                       All other DOMI reports   \n",
       "2     call taker                             GPS Panic Alarms   \n",
       "3     call taker                             Address Obtained   \n",
       "4     call taker                 Name or medic alert is known   \n",
       "...          ...                                          ...   \n",
       "3589  call taker  All Other DVERS personal residential alarms   \n",
       "3590  call taker                      DVERS Alarm maintenance   \n",
       "3591  call taker                     GPS tracked Panic Alarms   \n",
       "3592  call taker                                 DNA Warrant:   \n",
       "3593  call taker                                 DNA Warrant:   \n",
       "\n",
       "                                                    sop  \\\n",
       "0     [Listen to alarm, Acknowledge the alarm by pre...   \n",
       "1     [Create a call in every instance. Do not cance...   \n",
       "2     [Create a call, Remain on the line recording a...   \n",
       "3     [Run address on QBA:, If the person is negativ...   \n",
       "4     [Run name on CPIC, If the person is negative o...   \n",
       "...                                                 ...   \n",
       "3589  [Create a call, Check hazards which will show ...   \n",
       "3590  [See “Assist GP”  for a stand by keep the peac...   \n",
       "3591                                      [See AB-DOMI]   \n",
       "3592                        [See WARRAN (Warrants) SOP]   \n",
       "3593                        [See WARRAN (Warrants) SOP]   \n",
       "\n",
       "                                        filename  \n",
       "0            DE - 1033 - Officer in trouble.docx  \n",
       "1          AB - DOMI - Domestic in progress.docx  \n",
       "2          AB - DOMI - Domestic in progress.docx  \n",
       "3                AB - FOUNDP - Found Person.docx  \n",
       "4                AB - FOUNDP - Found Person.docx  \n",
       "...                                          ...  \n",
       "3589  AB - ALARMD - Domestic violence alarm.docx  \n",
       "3590  AB - ALARMD - Domestic violence alarm.docx  \n",
       "3591  AB - ALARMD - Domestic violence alarm.docx  \n",
       "3592             NW - DNA - DNA collection .docx  \n",
       "3593              RI - DNA - DNA collection.docx  \n",
       "\n",
       "[3594 rows x 4 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "situ_df = situ_df[ \n",
    "    (situ_df['role'] == 'call taker') \n",
    "    & (situ_df['situation'].str.len() > 0)\n",
    "].reset_index(drop = True)\n",
    "situ_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Listen to alarm Acknowledge the alarm by pressing 911 on the telephone Create a call at 4 56 Street'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "' '.join(situ_df.iloc[0, :]['sop'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(text,\n",
    "               min_token_len = 2,\n",
    "               allowed_pos = ['ADV', 'ADJ', 'VERB', 'NOUN', 'PART', 'PROPN']): \n",
    "    removal = ['-', r'i\\.e\\.']\n",
    "    res = list()\n",
    "\n",
    "    text = re.sub(r\"|\".join(removal), ' ', text.lower())\n",
    "    doc = nlp(text)\n",
    "    res += [token.lemma_ for token in doc \\\n",
    "           if token.pos_ in allowed_pos \\\n",
    "           # Spacy considers 'call' as a stop word, which is not suitable for our case\n",
    "           and not token.is_stop \\\n",
    "#                and token.text not in stop_words \\              \n",
    "#                and token.is_alpha \\\n",
    "           and len(token.lemma_) > min_token_len\n",
    "           ]\n",
    "    \n",
    "    return ' '.join(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dct_dtmatrix(sops):\n",
    "    corpus = [sop.split() for sop in map(preprocess, sops)]\n",
    "#     phrases = Phrases(corpus, min_count = 1, threshold = 1)\n",
    "#     bigram = Phraser(phrases)\n",
    "#     corpus = bigram(corpus)\n",
    "    dictionary = corpora.Dictionary(corpus)\n",
    "    doc_term_matrix = [dictionary.doc2bow(doc) for doc in corpus]\n",
    "    return doc_term_matrix, corpus, dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_term_bow, corpus, dictionary = get_dct_dtmatrix(situ_df['situation'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_mod = TfidfModel(doc_term_bow)\n",
    "doc_term_tfidf = tfidf_mod[doc_term_bow]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_df(df, name):\n",
    "    filename = '../data/interim/' + name\n",
    "    df.to_csv(filename, index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "hdp_tfidf_k15_t150_a1_g1 = HdpModel(corpus = doc_term_tfidf, id2word=dictionary, random_state = 2020)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "hdp_tfidf_k15_t150_a1_g01 = HdpModel(corpus = doc_term_tfidf, id2word=dictionary, gamma = 0.1, random_state = 2020)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "hdp_tfidf_k15_t150_a05_g01 = HdpModel(corpus = doc_term_tfidf, id2word=dictionary, \n",
    "                                      alpha = 0.5, gamma = 0.1, random_state = 2020)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "hdp_tfidf_k15_t300_a05_g01 = HdpModel(corpus = doc_term_tfidf, id2word=dictionary, T = 300, \n",
    "                                      alpha = 0.5, gamma = 0.1, random_state = 2020)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "hdp_tfidf_k30_t300_a05_g01 = HdpModel(corpus = doc_term_tfidf, id2word=dictionary, K = 30, T = 300, \n",
    "                                      alpha = 0.5, gamma = 0.1, random_state = 2020)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "hdp_tfidf_k30_t300_a01_g01 = HdpModel(corpus = doc_term_tfidf, id2word=dictionary, K = 30, T = 300, \n",
    "                                      alpha = 0.1, gamma = 0.1, random_state = 2020)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "hdp_tfidf_k30_t300_a1_g1 = HdpModel(corpus = doc_term_tfidf, id2word=dictionary, K = 30, T = 300, \n",
    "                                      random_state = 2020)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# coherence_hdp_tfidf = CoherenceModel(model=hdp_tfidf, texts=corpus, dictionary=dictionary, coherence='c_v')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# coherence_hdp_tfidf.get_coherence()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_topic(model, doc, md_type):\n",
    "    ppdoc = preprocess(doc)\n",
    "    doc_term_arr = dictionary.doc2bow(ppdoc.split())\n",
    "    if md_type == 'tfidf':\n",
    "        doc_term_arr = tfidf_mod[doc_term_arr]\n",
    "    try:\n",
    "        res = sorted(model[doc_term_arr], \n",
    "                      key = lambda x: x[1], \n",
    "                      reverse = True)[0][0]\n",
    "    except:\n",
    "        print(doc)\n",
    "        raise\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_topic2(model, doc, md_type):\n",
    "    ppdoc = preprocess(doc)\n",
    "    doc_term_arr = dictionary.doc2bow(ppdoc.split())\n",
    "    if md_type == 'tfidf':\n",
    "        doc_term_arr = tfidf_mod[doc_term_arr]\n",
    "    return sorted(model[doc_term_arr], \n",
    "                  key = lambda x: x[1], \n",
    "                  reverse = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_topic_clusters(model, md_type):\n",
    "    df = situ_df.copy()\n",
    "    df['topic_id'] = list(map(lambda x: get_topic(model, x, md_type), \n",
    "                              df['situation'].values.tolist()))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "situ_df['situation'].str.contains(r'Over \\$5000').sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocess('Over $5000')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>role</th>\n",
       "      <th>situation</th>\n",
       "      <th>sop</th>\n",
       "      <th>filename</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2161</th>\n",
       "      <td>call taker</td>\n",
       "      <td>Over $5000</td>\n",
       "      <td>[Create a call]</td>\n",
       "      <td>BI - THEFT.docx</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2182</th>\n",
       "      <td>call taker</td>\n",
       "      <td>Over $5000</td>\n",
       "      <td>[Create a call]</td>\n",
       "      <td>DE - THEFT.docx</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2206</th>\n",
       "      <td>call taker</td>\n",
       "      <td>Over $5000</td>\n",
       "      <td>[Create a call]</td>\n",
       "      <td>PO - THEFT.docx</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2227</th>\n",
       "      <td>call taker</td>\n",
       "      <td>Over $5000</td>\n",
       "      <td>[Create a call]</td>\n",
       "      <td>RM - THEFT.docx</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2242</th>\n",
       "      <td>call taker</td>\n",
       "      <td>Over $5000</td>\n",
       "      <td>[Create a call]</td>\n",
       "      <td>SC - THEFT.docx</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2257</th>\n",
       "      <td>call taker</td>\n",
       "      <td>Over $5000</td>\n",
       "      <td>[Create a call]</td>\n",
       "      <td>SQ - THEFT.docx</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2272</th>\n",
       "      <td>call taker</td>\n",
       "      <td>Over $5000</td>\n",
       "      <td>[Create a call]</td>\n",
       "      <td>SX - THEFT.docx</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2287</th>\n",
       "      <td>call taker</td>\n",
       "      <td>Over $5000</td>\n",
       "      <td>[Create a call]</td>\n",
       "      <td>UN - THEFT.docx</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2310</th>\n",
       "      <td>call taker</td>\n",
       "      <td>Over $5000</td>\n",
       "      <td>[Create a call]</td>\n",
       "      <td>WP - THEFT.docx</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2325</th>\n",
       "      <td>call taker</td>\n",
       "      <td>Over $5000</td>\n",
       "      <td>[Create a call]</td>\n",
       "      <td>WV - THEFT.docx</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            role   situation              sop         filename\n",
       "2161  call taker  Over $5000  [Create a call]  BI - THEFT.docx\n",
       "2182  call taker  Over $5000  [Create a call]  DE - THEFT.docx\n",
       "2206  call taker  Over $5000  [Create a call]  PO - THEFT.docx\n",
       "2227  call taker  Over $5000  [Create a call]  RM - THEFT.docx\n",
       "2242  call taker  Over $5000  [Create a call]  SC - THEFT.docx\n",
       "2257  call taker  Over $5000  [Create a call]  SQ - THEFT.docx\n",
       "2272  call taker  Over $5000  [Create a call]  SX - THEFT.docx\n",
       "2287  call taker  Over $5000  [Create a call]  UN - THEFT.docx\n",
       "2310  call taker  Over $5000  [Create a call]  WP - THEFT.docx\n",
       "2325  call taker  Over $5000  [Create a call]  WV - THEFT.docx"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "situ_df[situ_df['situation'] == 'Over $5000']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Over $5000\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-26-7493ad5a1a88>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0msitu_topics_hdp_tfidf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_topic_clusters\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhdp_tfidf_k30_t300_a1_g1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'tfidf'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0msitu_topics_hdp_tfidf\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-25-17fabb718481>\u001b[0m in \u001b[0;36mget_topic_clusters\u001b[1;34m(model, md_type)\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msitu_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     df['topic_id'] = list(map(lambda x: get_topic(model, x, md_type), \n\u001b[1;32m----> 4\u001b[1;33m                               df['situation'].values.tolist()))\n\u001b[0m\u001b[0;32m      5\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-25-17fabb718481>\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mget_topic_clusters\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmd_type\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msitu_df\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     df['topic_id'] = list(map(lambda x: get_topic(model, x, md_type), \n\u001b[0m\u001b[0;32m      4\u001b[0m                               df['situation'].values.tolist()))\n\u001b[0;32m      5\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-20-21f917e55012>\u001b[0m in \u001b[0;36mget_topic\u001b[1;34m(model, doc, md_type)\u001b[0m\n\u001b[0;32m      7\u001b[0m         res = sorted(model[doc_term_arr], \n\u001b[0;32m      8\u001b[0m                       \u001b[0mkey\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m                       reverse = True)[0][0]\n\u001b[0m\u001b[0;32m     10\u001b[0m     \u001b[1;32mexcept\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "situ_topics_hdp_tfidf = get_topic_clusters(hdp_tfidf_k30_t300_a1_g1, 'tfidf')\n",
    "situ_topics_hdp_tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "situ_topics_hdp_tfidf = situ_topics_hdp_tfidf \\\n",
    "                            .sort_values(by = ['topic_id'], ignore_index = True)\n",
    "situ_topics_hdp_tfidf#[situ_topics_hdp_tfidf['filename'].str.contains('Hit and Run')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raise Exception('stop here')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Do not change anything below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raise Exception('Stop here')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "calltaker_topic = calltaker_all.copy()\n",
    "calltaker_topic['topic_id'] = list(map(lambda x: get_topic(lda_20, x), \n",
    "                                                        calltaker_topic['sop'].values.tolist()))\n",
    "calltaker_topic[calltaker_topic['type'] == '1033']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "calltaker_topic = calltaker_topic.sort_values(by = ['topic_id', 'type', 'juri'], ignore_index = True)\n",
    "calltaker_topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "call_6 = calltaker_topic[calltaker_topic['topic_id'] == 6]\n",
    "call_6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "calltaker_topic['topic_id'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unwant = calltaker_topic[calltaker_topic['type'] == 'UNWANT']\n",
    "unwant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unwant['sop'].values.tolist()[-2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "call_6['sop'].values.tolist()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sents = call_6['sop'].tolist()[2]\n",
    "sents[1:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_entities(sent):\n",
    "    ent1 = ''\n",
    "    ent2 = ''\n",
    "    prv_tok_dep = ''\n",
    "    prv_tok_txt = ''\n",
    "    prefix = ''\n",
    "    mod = ''\n",
    "    for tok in nlp(sent):\n",
    "        if tok.dep_ != 'punct':\n",
    "            if tok.dep_ == 'compound':\n",
    "                prefix = tok.text\n",
    "                if prv_tok_dep == 'compound':\n",
    "                    prefix = prv_tok_text + ' ' + tok.text\n",
    "            if tok.dep_.endswith('mod'):\n",
    "                modifier = tok.text\n",
    "                if prv_tok_dep == 'compound':\n",
    "                    modifier = prv_tok_text + ' ' + tok.text\n",
    "            if tok.dep_.find('sub'):\n",
    "                ent1 = modifier + ' ' + prefix + ' ' + tok.text\n",
    "                prefix = ''\n",
    "                modifier = ''\n",
    "                prv_tok_dep = ''\n",
    "                prv_tok_text = ''\n",
    "            if tok.dep_.find('obj'):\n",
    "                ent2 = modifier + ' ' + prefix + ' ' + tok.text\n",
    "            \n",
    "            prv_tok_dep = tok.dep_\n",
    "            prv_tok_text = tok.text\n",
    "        return ent1.strip(), ent2.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# df_call_withtopic = df_dispatcher.copy()\n",
    "# df_call_withtopic.loc[:, 'topic_id'] = list(map(lambda x: get_topic(call_model_cv, x), \n",
    "#                                                 df_calltaker['sop'].values.tolist()))\n",
    "# df_call_withtopic = df_call_withtopic.sort_values(by = ['topic_id', 'juri'], ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# df_call_withtopic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# empty = pd.DataFrame()\n",
    "# df1 = pd.DataFrame({'type': ['type1', 'type2'], 'value': [1, 2]})\n",
    "# empty = empty.append(df1)\n",
    "# empty = empty.append(df1)\n",
    "# empty"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reflection of DRUGS coherence score\n",
    "- the coherence score is very high for the one-topic model\n",
    "- this makes sense, because we are looking at docs under the same type \"DRUGS\"\n",
    "\n",
    "#### Question\n",
    "- While the model assigns the documents with the correct topic, does this necessarily mean the documents are similar enough to be consolicated?\n",
    "- LDA in not stable.  How will this instability affect us?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type_list = sop_df['type'].values.tolist()\n",
    "type_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "type_list = sop_df['type']\n",
    "res = pd.DataFrame()\n",
    "for event_type in type_list:\n",
    "    dct = load_event(event_type)\n",
    "    event_row = sop_df[sop_df['type'] == event_type]\n",
    "    juri_to_filename = dict(zip(event_row['juri'].values[0], \n",
    "                            event_row['filename'].values[0]))\n",
    "    juris, roles, sops, types = list(), list(), list(), list()\n",
    "    for juri, role_sop in dct.items():\n",
    "        for role, sop in role_sop.items():\n",
    "            juris.append(juri)\n",
    "            roles.append(role)\n",
    "            sops.append(sop)\n",
    "            types.append(event_type)\n",
    "    typedf = pd.DataFrame({'type': types, 'juri': juris, 'role': roles, 'sop': sops})\n",
    "    typedf['filename'] = typedf['juri'].apply(lambda x: juri_to_filename[x])\n",
    "    df_calltaker = typedf[typedf['role'] == 'call taker']\n",
    "    df_dispatcher = typedf[typedf['role'] == 'dispatcher']\n",
    "    print(df_calltaker.shape)\n",
    "    print(df_dispatcher.shape)\n",
    "\n",
    "    for df in [df_calltaker, df_dispatcher]:\n",
    "        if len(df) == 0:\n",
    "            continue\n",
    "        print('Start working on:', event_type, df['role'].unique())\n",
    "        doc_term_matrix, corpus, dictionary = get_dct_dtmatrix(df['sop'])\n",
    "        coherence_cv = topics_with_coherence(doc_term_matrix, corpus, dictionary, \n",
    "                                            df['sop'].values.tolist())\n",
    "        best_model_cv = coherence_cv.iloc[1:, :].sort_values('coherence_score')['model'].tolist()[-1]\n",
    "        df_with_topic = df.copy()\n",
    "        df_with_topic.loc[:, 'topic_id'] = list(map(lambda x: get_topic(best_model_cv, x), \n",
    "                                                        df['sop'].values.tolist()))\n",
    "        df_with_topic = df_with_topic.sort_values(by = ['topic_id', 'juri'], ignore_index = True)\n",
    "        res = res.append(df_with_topic)\n",
    "        print('Finish working on:', event_type, df['role'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "ress = res.reset_index(drop = True)\n",
    "ress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime \n",
    "dt = datetime.now().strftime('%Y-%m-%dT%H_%M_%S')\n",
    "cwd = os.getcwd()\n",
    "os.chdir(notebook_dir)\n",
    "ress.to_csv(f'../data/interim/sop_topics_{dt}.csv', index = False)\n",
    "os.chdir(cwd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(type_list.values.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ress[ (ress['type'] == 'MISCH') & (ress['role'] == 'call taker')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ress[ (ress['type'] == 'MISCH') & (ress['role'] == 'dispatcher')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "ress[ (ress['type'] == 'ANIMAL') & (ress['role'] == 'call taker')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ress[ (ress['type'] == 'DRUGS') & (ress['role'] == 'call taker')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ress[ (ress['type'] == 'DRUGS') & (ress['role'] == 'call taker')]['sop'].values.tolist()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_coherence = topics_with_coherence(dt_matrix_all, corpus_all, dictionary_all, N = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_coherence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure(figsize = (12, 8))\n",
    "# plt.plot(all_coherence.loc[:, 'num_topic'].values, all_coherence.loc[:, 'coherence_score'].values)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
